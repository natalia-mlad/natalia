% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/web-scrape.R
\name{scrapeurl}
\alias{scrapeurl}
\title{Scrape all the internal pages of a relatively simple website}
\usage{
scrapeurl(my_url, path)
}
\arguments{
\item{my_url}{url of the head/start page}

\item{path}{dir path where to save the html files}
}
\value{
a character vector of all the urls scraped
}
\description{
Relies on pages being linked to each other.
Has not been optimised (TODO), but works pretty smoothly in practice!
}
\examples{
\dontrun{
scrapeurl("https://loal.app/", path_home("OneDrive/PhD Psychology/loal-website-scrape"))
}

}
