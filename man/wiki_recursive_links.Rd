% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wiki-scrape.R
\name{wiki_recursive_links}
\alias{wiki_recursive_links}
\title{Recurse through links of pages (of links)^{n} of a Wikipedia page}
\usage{
wiki_recursive_links(url, depth = 2)
}
\arguments{
\item{url}{a wikipedia url (absolute or relative)}

\item{depth}{numeric, default is 2. Depth of 1 means just the links on the existing page are found; depth of 2 means the links of the links; and so on.}
}
\value{
a nested tibble with columns page and links
}
\description{
Great for creating a dataset for network analysis.
Depth of 1 means just the links on the existing page are found; depth of 2 means the links of the links; and so on.
}
\details{
Please note, this function gets expensive quickly (i.e., several hours) at depth 3 for pages with lots of links (i.e., 300+).
Also, while some care has been taken to optimise it, it currently considers pages that redirect to each other as different, thus resulting in unnecessary repetion (TODO)
(e.g., "/wiki/Principle_of_Compositionality" and "wiki/Principle_of_compositionality")
}
